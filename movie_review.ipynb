{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_review.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMI+V/yM8Nf+Leblqgvl0N+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asimMahat111/movie-review-Sentiment-Analsysis/blob/master/movie_review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilXnhaQMsiC8",
        "colab_type": "code",
        "outputId": "414154d3-be4e-4414-ad2d-fe2a06ef9e7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "#importing necessary modules\n",
        "from keras.datasets import imdb #we will use dataset from imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "MAX_LENGTH = 250\n",
        "BATCH_SIZE=64\n",
        "\n",
        "(training_data,training_labels),(testing_data,testing_labels)= imdb.load_data(num_words= VOCAB_SIZE)#loaded IMDB data\n",
        "# training_data[1]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGNTV3EJuTBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#our training data and testing data are of max length 250\n",
        "my_training_data = sequence.pad_sequences(training_data,MAX_LENGTH)\n",
        "my_testing_data = sequence.pad_sequences(testing_data,MAX_LENGTH)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfHyOTVzusGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# making our rnn_model architecture\n",
        "our_model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Embedding(VOCAB_SIZE,32),\n",
        "            tf.keras.layers.LSTM(32),\n",
        "            tf.keras.layers.Dense(1,activation='relu') # we have used 'relu' activation function becasue our output is either '0' or '1'\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahJg8vvYvSqm",
        "colab_type": "code",
        "outputId": "8e35a442-e976-4686-d174-305b80ba8384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "our_model.summary() # looking the architecture of our model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          2834688   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 2,843,041\n",
            "Trainable params: 2,843,041\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsdNOdmKvfDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compiling our model,loss function and optimizer can be changed\n",
        "our_model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ683PN5vfCD",
        "colab_type": "code",
        "outputId": "145a87eb-3a54-4f1c-feaa-cf6a2d987fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "training = our_model.fit(my_training_data,training_labels,epochs=5,validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 0.5829 - acc: 0.7613 - val_loss: 0.4306 - val_acc: 0.8606\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 0.3902 - acc: 0.8887 - val_loss: 0.3430 - val_acc: 0.8812\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 0.3230 - acc: 0.9122 - val_loss: 0.4266 - val_acc: 0.8748\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 47s 75ms/step - loss: 0.2702 - acc: 0.9282 - val_loss: 0.3717 - val_acc: 0.8874\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 45s 73ms/step - loss: 0.2535 - acc: 0.9452 - val_loss: 0.4195 - val_acc: 0.8776\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4vkFmE_w5zi",
        "colab_type": "code",
        "outputId": "85593035-eafb-4912-9626-650143fb6497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "validation_test= our_model.evaluate(my_testing_data,test_labels)\n",
        "print(validation_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 16s 21ms/step - loss: 0.5181 - acc: 0.8740\n",
            "[0.518078088760376, 0.8740400075912476]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8GEs3NDzSEY",
        "colab_type": "code",
        "outputId": "29405475-167d-47ae-cccc-0e9999ddbcc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#predicting \n",
        "word_index = imdb.get_word_index() #getting the trained words from keras imdb dataset and storing it in word_index variable\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], MAX_LENGTH)[0]\n",
        "\n",
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)#the text is encoded using encode_text function\n",
        "# print(encoded)\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = our_model.predict(pred) \n",
        "  print(result[0])\n",
        "\n",
        "positive_review = \"The movie is awesome,I loved it\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.24428795]\n",
            "[0.5252452]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}